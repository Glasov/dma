# Псевдокод, О-большая и бинарный поиск

## Алгоритмы и псевдокод
Алгоритм - четкая последовательность действий, выполнение которой дает какой-то заранее известный результат.

(Кстати, для меня оказалось открытием, что слово "алгоритм" произошло от имени, судя по википедии)

<img width="576" alt="image" src="https://github.com/user-attachments/assets/b1f45b11-f891-4c22-a311-3e411a2973b6" />

Есть несколько способов описывать алгоритмы, но основные - псевдокод и блок-схемы.
Чаще всего используют всё же псевдокод, так как он практичнее: с ним можно упустить детали реализации и сконцентрироваться на идее алгоритма.

Примеры:

<img width="450" alt="image" src="https://github.com/user-attachments/assets/b76758d8-367c-4a65-9aa9-cc066595d700" />

И

<img width="446" alt="image" src="https://github.com/user-attachments/assets/311dd02e-798f-4c15-8787-224192476902" />

В обоих примерах есть функции, реализация которых не дана, но по названию и контексту статьи можно понять, что они делают.

## О-большая

Почти каждую задачу можно решить несколькими способами, и, соответственно, можно написать разные алгоритмы. Но как понять, какой из них лучше?

В этом помогает нотация О-большая: она позволяет сравнивать не конкретное время выполнения (потому что оно сильно зависит от железа), а в терминах роста времени выполнения при увеличении размера входных данных.

Если формализовать: O(f(n)) — это способ описать, как быстро растет время работы алгоритма при увеличении размера входных данных (n). Мы говорим, что алгоритм работает за O(f(n)), если его время выполнения растет не быстрее, чем f(n), с точностью до константы.

Пирмер: если алгоритм работает за 3n + 5 шагов, мы говорим, что он O(n), потому что константы (3 и 5) не важны при больших n.

Ещё примеры:

<b>O(1)</b>: доступ к элементу массива по индексу, время не зависит от размера массива

<b>O(n)</b>: поиск элемента в неотсортированном массиве, так как нужно пройти по всем n элементам массива

<b>O(n²)</b>: пузырьковая сортировка.

```python
def bubble_sort(arr):
    for n in range(len(arr) - 1, 0, -1):
        swapped = False  

        for i in range(n):
            if arr[i] > arr[i + 1]:
                arr[i], arr[i + 1] = arr[i + 1], arr[i]
                swapped = True
        if not swapped:
            break
```

Тут у нас есть два цикла: внешний и вложенный

Каждая итерация вложенного цикла работает за O(1), так как она не зависит от длины массива: мы производим сложения, присваивания и сравнения.

На каждую итерацию внешнего цикла приходится n итераций вложенного, и всего внешний производит n итераций.

То есть для расчёта итогового времени работы алгоритма мы умножим: O(n) * O(n) * O(1) = O(n²)

## Бинарный поиск

Бинарный поиск — это алгоритм, который позволяет быстро находить элемент в отсортированном массиве или монотонной функции.

Его ключевая особенность — он работает за время O(log n), что делает его гораздо эффективнее линейного поиска (который работает за O(n)) для больших данных (например, для миллиарда-двух-трёх эллементов).

<b>Очень важно, чтобы массив или функция были монотонны, иначе бираный поиск не будет корректно работать.</b>

Его идея - каждом шаге делить массив на две части и отбрасывать ту, где искомый элемент точно не может находиться.

Как он примерно выглядит:

Определяем границы поиска: левую (L) и правую (R).

Найдим середину: M = (L + R) / 2.

Сравниваем элемент в середине с искомым значением:

Если элемент равен искомому, поиск завершён.

Если элемент больше, ищем в левой половине (R = M - 1).

Если элемент меньше, ищем в правой половине (L = M + 1).

Повторяем, пока L не станет больше R.

Пример:

Дан отсортированный массив: `[1, 3, 5, 7, 9, 11, 13]`. Найдём индекс числа `9`.

Шаг 1:
`L = 0, R = 6.`

`M = 3, arr[3] = 7 < 9 → ищем в правой половине.`

Шаг 2:
`L = 4, R = 6.` // здесь L = 4, так как мы точно знаем, что в отрезке [0, 3] нету искомого элемента

`M = 5, arr[5] = 11 > 9 → ищем в левой половине.`

Шаг 3:
`L = 4, R = 4.`

`M = 4, arr[4] = 9 → элемент найден, индекс 4.`

Если бы по индексу 4 было другое число, мы бы получили ситуацию, где L > R: было бы либо L = 5, R = 4, либо L = 4, R = 3, и цикл бы завершился.

Что касается асимптотики:
На каждом шаге бинарный поиск уменьшает диапазон поиска вдвое. Это значит, что количество шагов, необходимых для нахождения элемента, равно количеству раз, которое нужно поделить n на 2, чтобы получить 1, а это и есть log₂(n).

То есть алгоритм работает за O(log₂(n))

При этом важно понять: если бы каждая итерация выполнялась за O(f(n)) (например, нужно было как-то по-хитрому расчитывать значения функции), то алгоритм бы работал за O(f(n)*log₂(n)): всего log₂(n) итераций, каждая по f(n)
