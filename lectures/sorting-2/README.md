# Сортировки (опять)

Думаю, все знают, что такое сортировка и зачем они нужны. Пример сортировки - сортировка пузырьком.

Однако не все сортировки раные, есть и равнее, которые работают намного быстрее, и многие подходят для тех или иных случаев: это зависит от их свойств.

## Свойства сорировок
Всего есть 4 основных свойств:

### Стабильность
Сортировка считается стабильной, если она сохраняет относительный порядок равных элементов после сортировки.

Если по-человечески, то посмотрим на пример:

<img width="476" alt="image" src="https://github.com/user-attachments/assets/6421664b-93d0-4696-81cc-dc9f258f7f67" />

Список карт мы можем отсортировать двумя способами, и каждый из них правильно упорядочит элементы, однако, относительный порядок пятёрок - то есть сначала идут черви, а потом пики - сохраняется только во втором случае.

Получается, что стабильная сортировка ГАРАНТИРУЕТ, что результат сортировки будет как во втором случае, а нестабильная - нет.

### Адаптивность

Адаптивность - это насколько сортировка эффективна при почти неотсротированных или почти отсортированных данных.

Например, адаптивная сортировка может за разное время отсортировать эти два массива (в первом есть отсортированные подотрезков, в первом - они очень короткие, и их много)

<img width="459" alt="image" src="https://github.com/user-attachments/assets/68236fb8-3186-49b5-9249-e45d13564935" />

### In-place
Сортировка называется In-place, если она не требует дополнительной памяти (например, когда она мутирует изначальный массив, не создавая копию)

### Временная сложность
Сортировка может показывает разный результат в лучшем, худшем и среднем случаях. В таблице приведены асимптотики нескольких алгоритмов сортировки.

<img width="448" alt="image" src="https://github.com/user-attachments/assets/a5ea3cb4-327d-47f4-9a7e-ae61beb108fc" />

## Quicksort
Коли у нас есть в тиблице быстрая сортировка, давайте про неё и поговорим. Это стандартная сортировка в С++, и в целом она работает хорошо для большинства данных.

### Описание алгоритма
Этот алгоритм является рекурсивным, и выглядит примерно следующим образом:

1) Получаем массив и границы для сортировки: arr, l, r
3) Если l >= r или l < 0 (некорректные границы массива), выходим из функции
5) Выбираем опорный элемент (pivot) по индексу p
6) Все элементы меньшие pivot перебрасываем слева от него, остальные - справа
7) Рекурсивно сортируем отрезки [l, p - 1], [p + 1, r]

Пример:

arr = [3, 7, 8, 5, 2]

arr.length = 5

l = 0

r = 5

qs - функция сортировки

qs(l, r) - первый запуск

для простоты будем выбирать в качестве опорного последний элемент массива (это нехорошо)

arr[l, r) = arr[0, 5) = [3, 7, 8, 5, 2]

                                     ^ - опорный элемент

arr[l, r) = [2, 3, 7, 8, 5] после "переброса"

вызываем qs(l,p - 1) = qs(0, -1) - завершается (неправильные границы)

qs(p+1,r) = qs(1, 5)

arr[l, r) = arr[1, 5) = [3, 7, 8, 5]

                                  ^ - опорный элемент

arr[l, r) = [3, 5, 7, 8] после "переброса"

qs(l,p-1) = qs(1,1) - завершается (неправильные границы)

qs(p+1,r) = qs(3,5)

arr[l, r) = arr[3, 5) = [7, 8]

                            ^ - опорный элемент

arr[l, r) = [7, 8] после "переброса"

qs(l,p-1) = qs(3,2) - завершается (неправильные границы)

qs(p+1,r)=p(4,5)

arr[l, r) = arr[4, 5) = [8]

                         ^ - опорный элемент

arr[l, r) = [8] после "переброса"

qs(l,p-1) = qs(4,3) - завершается (неправильные границы)

qs(p+1,r)=p(5,5) - завершается (неправильные границы)

### Асимптотика
По скорости:

**В худшем случае**

Если на каждом шаге pivot оказывается минимальным или максимальным элементом, массив делится на части размером 1 и n-1.

Глубина рекурсии становится n (так как на каждом шаге обрабатывается на 1 элемент меньше).

На каждом уровне выполняется O(n) операций.

В итоге получаем O(n²)

Чтобы избежать такой случай, обычно выбирают в качестве опорного случайный элемент на отрезке.

**В лучшем и обычном случае**

Если на каждом шаге pivot делит массив на примерно равные части, глубина рекурсии будет log₂ n (так как массив делится пополам на каждом уровне).

На каждом уровне рекурсии выполняется O(n) операций (проход по всем элементам для разбиения).

В итоге получаем O(n*log(n))

По памяти:

Так как мы создаём переменные при каждом рекурсивном вызове и НЕ переиспользуем их, у нас получается следующая картина:

В худшем случае у нас получается O(n) - из-за глубины рекурсии

В лучшем - O(log(n)), тоже из-за глубины рекурсии

### Свойства
* In-place
* Нестабильная
* Неадаптивная (в классичкой реализации может плохо работать на почти отсортированных или почти не отсортированных данных)

## Merge sort

Сортировка слиянием использует несколько идей для сортировки массива:

* Если у нас есть два отсортированных массива, мы можем их слить за O(n + m), где n и m - длины этих массивов, получив отсортированный массив.
* Если разделить массив пополам и отсортировать каждую из частей, то можно будет слить их обратно и получить отсортированный массив.
* Массив из одного элемента отсортирован.

### Описание алгоритма

**Разделение:**

Исходный массив рекурсивно делится на две примерно равные части до тех пор, пока не останутся подмассивы длиной в 1 элемент.

**Слияние:**

На обратном ходу рекурсии пары подмассивов сливаются в упорядоченные последовательности.

Элементы сравниваются попарно, и меньший помещается в результирующий массив.

Процесс повторяется для всех уровней рекурсии, пока не получится единый отсортированный массив.

Пример:

arr = [3, 7, 8, 5, 2]

Делим его пополам:

[3, 7] [8, 5, 2]

Отсортируем каждый подмассив отдельно и потом сольём их.

[3, 7] делим пополам

[3] [7] - сливаем, получаем [3, 7]

Теперь отсортируем второй массив:

[8, 5, 2]

[8] [5, 2]

     [5] [2]

     [2, 5]
[2, 5, 8]

Сливаем два отсортированных подмассива: 
[2, 3, 5, 7, 8]

### Асимптотика

На каждом шаге массив делится на две примерно равные части. Это продолжается до тех пор, пока не останутся подмассивы из одного элемента (базовый случай рекурсии).

Глубина рекурсии равна log(​n), так как на каждом уровне массив делится пополам.

На каждом уровне рекурсии происходит слияние двух отсортированных подмассивов. Слияние требует O(n) операций, так как нужно пройтись по всем элементам обоих подмассивов.

Поскольку уровней рекурсии log2(n), а на каждом уровне выполняется O(n) операций, общая временная сложность составляет: O(nlogn)

### Память

В основном память занимает массив для слияния. Если переиспользовать его, получим O(n)

## Реализация

### Merge sort

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr

    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])

    result = []
    i = j = 0
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1

    result += left[i:]
    result += right[j:]
    return result

arr = [3, 6, 8, 10, 1, 2, 1]

print(merge_sort(arr))
```

### Quicksort

```python
def quicksort(arr):
    if len(arr) <= 1:
        return arr

    pivot = arr[-1]

    left = []
    right = []

    for i in range(len(arr) - 1):
        if arr[i] <= pivot:
            left.append(arr[i])
        else:
            right.append(arr[i])

#      qs(l,p-1)                p      qs(p+1, r)
    return quicksort(left) + [pivot] + quicksort(right)

def quicksort_with_partition(arr, low, high):
    if low < 0:
        return

    if low < high:
        pivot_index = partition(arr, low, high)

        quicksort_with_partition(arr, low, pivot_index - 1)
        quicksort_with_partition(arr, pivot_index + 1, high)

def partition(arr, low, high):
    pivot = arr[high]

    i = low - 1

    for j in range(low, high):
        if arr[j] <= pivot:
            i += 1
            arr[i], arr[j] = arr[j], arr[i]

    arr[i + 1], arr[high] = arr[high], arr[i + 1]

    return i + 1

arr1 = [3, 6, 8, 10, 1, 2, 1]
arr2 = [3, 6, 8, 10, 1, 2, 1]
quicksort_with_partition(arr1, 0, len(arr1) - 1)
print(arr1)
print(quicksort(arr2))
print(arr2)
```
